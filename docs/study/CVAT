Intel CVAT (Computer Vision Annotation Tool)은 비디오 및 이미지 데이터에 대한 어노테이션(Annotation) 작업을 위한 강력한 오픈 소스 도구입니다.

  현재 Nexus-Edge 프로젝트의 docs/labeling_guide.md에 따르면, CVAT는 바코드 검출(Barcode Detection)을 위한 YOLOv11n 학습용 데이터셋을 구축하는 
  데 사용되고 있습니다.

  학습을 시작하기 위해 다음 단계 중 어떤 것부터 진행하시겠습니까?
   
   1. 환경 설정: cvat.ai (https://app.cvat.ai/) 클라우드 버전 사용법 또는 로컬(Docker) 설치 방법 확인
   2. CVAT 개요 및 주요 기능 파악: CVAT가 제공하는 강력한 어노테이션 도구(AI 보조 라벨링, 자동 추적 등)와 장점 알아보기
   3. 바코드 데이터셋 생성 실습: 현재 프로젝트 가이드에 따라 실제 이미지를 업로드하고 라벨링(BBox)하여 YOLO 포맷으로 내보내는 과정 진행        
   4. 고급 기능 활용: AI 모델을 연동하여 자동으로 라벨을 생성하는 'Automatic Annotation' 기능 살펴보기


WSL2 Ubuntu 24.04 환경에서 Intel CVAT를 로컬에 설치하는 단계별 가이드입니다. CVAT는 Docker 컨테이너 기반으로 구동되므로,
 Docker 설치가 핵심입니다.

  1. 사전 준비 (Docker 및 종속성 설치)
  WSL2 터미널에서 다음 명령어를 실행하여 시스템을 업데이트하고 필요한 도구들을 설치합니다.


   1 # 시스템 업데이트
   2 sudo apt-get update && sudo apt-get upgrade -y
   3
   4 # 필수 패키지 설치
   5 sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release git

  2. Docker 및 Docker Compose 설치
  Ubuntu 24.04 공식 저장소를 사용하여 Docker를 설치합니다.


    1 # Docker 공식 GPG 키 추가
    2 sudo install -m 0755 -d /etc/apt/keyrings
    3 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
    4 sudo chmod a+r /etc/apt/keyrings/docker.gpg
    5
    6 # 저장소 설정
    7 echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
$(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
   11
   12 # Docker 엔진 설치
   13 sudo apt-get update
   14 sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
   15
   16 # 현재 사용자를 docker 그룹에 추가 (sudo 없이 사용 가능하도록)
   17 sudo usermod -aG docker $USER
  > 주의: usermod 적용을 위해 WSL을 재시작(wsl --shutdown 후 다시 실행)하거나 로그아웃 후 다시 로그인해야 합니다.

  3. CVAT 소스 코드 가져오기
  GitHub에서 CVAT 최신 버전을 복제합니다.


   1 git clone https://github.com/cvat-ai/cvat
   2 cd cvat

  4. CVAT 실행 (Docker Compose)
  처음 실행 시 이미지를 다운로드하고 빌드하는 데 시간이 다소 소요될 수 있습니다.

   1 docker compose up -d


  5. 관리자 계정(Superuser) 생성
  설치가 완료되면 웹 UI에 로그인할 관리자 계정을 생성해야 합니다.

   1 docker exec -it cvat_server python3 manage.py createsuperuser
  명령어 실행 후 이름, 이메일, 비밀번호를 순서대로 입력하세요.


  6. 접속 및 확인
  설치가 정상적으로 완료되었다면, 브라우저를 열고 다음 주소로 접속합니다.
   - 주소: http://localhost:8080

  ---


  💡 팁: 반자동 라벨링(Serverless) 기능을 쓰려면?
  AI 모델을 사용하여 자동으로 라벨을 제안하는 기능을 쓰려면 nuclio가 포함된 환경을 추가로 실행해야 합니다.


   1 # Nuclio와 함께 실행 (자동 라벨링 기능 활성화)
   2 docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml -f gpu.yml up -d



✦ Nuclio는 고성능 서버리스(Serverless) 이벤트 처리 플랫폼입니다.


  CVAT 환경에서 Nuclio는 AI 모델을 실행하고 관리하는 핵심 엔진 역할을 합니다. 쉽게 설명하면, CVAT라는 '웹 도구'가 AI 모델(YOLO, Mask R-CNN
  등)이라는 '똑똑한 비서'를 부려먹기 위해 사용하는 중간 다리라고 보시면 됩니다.

  1. CVAT에서의 주요 역할
  CVAT에서 "Automatic Annotation(자동 어노테이션)"이나 "AI Tools"를 클릭하면 내부적으로 다음과 같은 일이 일어납니다.


   1. 모델 호스팅: 사용자가 준비한 AI 모델을 개별적인 컨테이너(Serverless Function)로 띄워둡니다.
   2. API 제공: CVAT 서버가 이미지를 Nuclio에 보내면, Nuclio가 모델을 실행해 결과를 다시 CVAT로 전달합니다.
   3. 동적 확장: 모델이 필요할 때만 리소스를 사용하고, 사용하지 않을 때는 대기 상태로 두어 효율적으로 관리합니다.


  2. 왜 Nuclio를 쓰는가? (장점)
   * 실시간성 (High Performance): 데이터 처리가 매우 빨라 실시간 비디오 스트리밍이나 대량의 이미지 처리에 적합합니다.
   * GPU 지원: AI 모델 성능에 필수적인 NVIDIA GPU 가속을 완벽하게 지원합니다.
   * 다양한 언어 지원: Python뿐만 아니라 Go, Java, NodeJS 등으로 작성된 모델도 실행 가능합니다.
   * 자동화: 수동으로 상자를 그리는 대신, Nuclio에 올라간 모델이 "이건 바코드야"라고 먼저 제안해주므로 작업 시간을 1/10로 줄여줍니다.


  3. Nexus-Edge 프로젝트와의 연결고리
  현재 진행 중인 바코드 검출(Barcode Detection) 프로젝트에서 Nuclio를 활용하면 다음과 같은 이점이 있습니다.


   * Pre-labeling: 이미 학습된 일반적인 바코드 모델을 Nuclio에 올려두면, 새로운 데이터를 업로드했을 때 자동으로 바코드 영역을 찾아 박스(BBox)를
     그려줍니다.
   * 학습 데이터 가공 속도 향상: 수동으로 1,000장을 그리는 대신, 모델이 찾은 900장을 검토만 하고 나머지 100장만 직접 수정하면 됩니다.

  🚀 설치 시 고려사항
  로컬(WSL2)에 설치할 때 Nuclio를 포함하려면 단순히 docker compose up만 하는 것이 아니라, Serverless 컴포넌트를 함께 활성화해야 합니다.


   1 # Nuclio를 포함하여 CVAT 실행 (WSL2에서 권장)
     # docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml up -d
   docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml -f gpu.yml up -d


  WSL2에서 GPU 가속(NVIDIA Docker)을 사용하기 위한 추가 설정

  ✦ WSL2 환경의 Docker 컨테이너에서 GPU를 사용하기 위해서는 NVIDIA Container Toolkit 설치와 Docker Runtime 설정이 필수입니다. Ubuntu 24.04
  기준으로 단계별 방법을 안내해 드립니다.


  1. Windows 호스트 드라이버 확인
  먼저 Windows 본체에 최신 NVIDIA 드라이버가 설치되어 있어야 합니다. (WSL 전용 드라이버를 따로 설치할 필요 없이, 최신 Game Ready 또는 Studio
  드라이버면 충분합니다.)


  WSL 터미널에서 아래 명령어가 작동하는지 확인하세요.
   1 nvidia-smi
  GPU 정보가 출력된다면 하드웨어 준비는 끝난 것입니다.

  2. NVIDIA Container Toolkit 설치 (Ubuntu 24.04)
  Docker가 GPU를 인식할 수 있도록 툴킷을 설치합니다.


   1 # GPG 키 및 저장소 설정
   2 curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o \
/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
   3 curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
   6
   7 # 설치
   8 sudo apt-get update
   9 sudo apt-get install -y nvidia-container-toolkit

  3. Docker 설정 및 재시작
  Docker가 NVIDIA 런타임을 사용하도록 설정합니다.

   1 # Docker 설정 업데이트
   2 sudo nvidia-ctk runtime configure --runtime=docker
   3
   4 # Docker 서비스 재시작
   5 sudo systemctl restart docker

  4. GPU 인식 테스트
  컨테이너 내부에서 GPU가 정상적으로 인식되는지 확인합니다.


   1 docker run --rm --runtime=nvidia --gpus all nvidia/cuda:12.0.1-base-ubuntu22.04 nvidia-smi
  여기서 다시 한번 GPU 정보 표가 출력되어야 합니다.

  ---
  WSL2 환경에서 GPU 가속을 활성화하기 위해 다음 두 가지 단계를 수행해 주세요.

  1. gpu.yml 파일 생성
  CVAT 루트 디렉토리에 gpu.yml 파일을 만들어 GPU를 할당해야 합니다.

    1 services:
    2   cvat_server:
    3     runtime: nvidia
    4     environment:
    5       - NVIDIA_VISIBLE_DEVICES=all
    6       - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
    7     deploy:
    8       resources:
    9         reservations:
   10           devices:
   11             - driver: nvidia
   12               count: all
   13               capabilities: [gpu, utility]
   14
   15   cvat_worker_annotation:
   16     runtime: nvidia
   17     environment:
   18       - NVIDIA_VISIBLE_DEVICES=all
   19       - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
   20     deploy:
   21       resources:
   22         reservations:
   23           devices:
   24             - driver: nvidia
   25               count: all
   26               capabilities: [gpu, utility]
   27
   28   nuclio:
   29     runtime: nvidia
   30     environment:
   31       - NVIDIA_VISIBLE_DEVICES=all
   32       - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
   33     deploy:
   34       resources:
   35         reservations:
   36           devices:
   37             - driver: nvidia
   38               count: all
   39               capabilities: [gpu, utility]

   인식확인
   docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml -f gpu.yml config | grep -A 10 "reservations"

  2. CVAT 실행 (Nuclio 포함)
   1 # 1. 기존 설정 제거 (오류 무시하고 강제 종료)
   2 docker compose down --remove-orphans
   3
   4 # 2. 수정된 설정으로 다시 실행
   5 docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml -f gpu.yml up -d

  ---
정확한 테스트를 위해 NVIDIA 공식 테스트 이미지를 사용해야 합니다. 아래 명령어를 실행해 보세요.


  1. 공식 테스트 이미지로 확인
   1 docker run --rm --runtime=nvidia --gpus all nvidia/cuda:12.0.1-base-ubuntu22.04 nvidia-smi
   - 만약 default-runtime이 잘 설정되었다면 --runtime=nvidia를 빼고 실행해도 됩니다:
   1 docker run --rm --gpus all nvidia/cuda:12.0.1-base-ubuntu22.04 nvidia-smi


  2. 만약 위 명령어가 성공한다면?
  이제 CVAT로 돌아가서 설정을 마무리하면 됩니다. gpu.yml 파일에서 capabilities에 utility가 포함되어 있으므로, CVAT 컨테이너 내에서도 드라이버
  유틸리티를 쓸 수 있게 됩니다.

2. CVAT 실행 명령어
  이제 모든 설정 파일을 한 번에 불러와서 실행합니다.
docker compose down --remove-orphans
docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml -f gpu.yml up -d

    3. GPU 인식 확인 (ldconfig 방식)

  컨테이너가 뜬 후, 아래 명령어로 NVIDIA 라이브러리가 로드되었는지 최종 확인하세요. (WSL2에서는 이게 더 정확합니다.)

   1 docker exec -it cvat_worker_annotation ldconfig -p | grep nvidia

 ✦ 드디어 성공입니다! 🎉


  ldconfig -p | grep nvidia 명령어로 libnvidia-ptxjitcompiler.so.1와 libnvidia-ml.so.1 라이브러리 목록이 출력된 것은 Docker 컨테이너가
  호스트(WSL2)의 NVIDIA 드라이버를 완벽하게 로드했음을 의미합니다.


  ls /dev/nvidia*가 안 나왔던 이유는 WSL2의 Docker가 실제 장치 노드 대신 이 라이브러리들(vGPU 방식)을 통해 GPU 가속을 처리하기 때문입니다.

  🚀 이제 무엇을 할 수 있나요?


  이제 CVAT에서 GPU를 사용하는 Intel CVAT 학습 및 바코드 데이터셋 생성의 다음 단계로 넘어갈 수 있습니다.


   1. 웹 접속: 브라우저에서 http://localhost:8080에 접속하여 로그인합니다.
   2. 프로젝트 생성: Barcode Detection 프로젝트를 만들고 라벨(barcode)을 추가합니다.
   3. 데이터 업로드: 이미지를 업로드하고 태스크를 생성합니다.
   4. 자동 라벨링(AI 기능) 테스트:
       * Models 탭에서 사용 가능한 AI 모델(예: YOLO, Mask R-CNN 등)이 있는지 확인합니다.
       * Annotate -> Automatic Annotation 기능을 사용하여 GPU 가속으로 얼마나 빠르게 바코드를 잡아내는지 확인해 보세요!


  💡 팁: Nuclio 모델 배포가 필요하다면?
  만약 기본 모델 외에 YOLOv11 같은 최신 모델을 CVAT에 직접 올리고 싶다면 별도의 모델 서버 설정이 필요합니다.


  현재 상태에서 바코드 데이터를 직접 그리며 시작하시겠습니까, 아니면 AI 자동 라벨링 모델을 먼저 배포하는 방법부터 알아보시겠습니까?(어떤 선택을
  하셔도 좋습니다!)

  추가 확인사항 (WSL2 전용)
  WSL2에서 간혹 메모리 부족으로 GPU 컨테이너가 죽는 경우가 있습니다. 사용자 홈 디렉토리(C:\Users\사용자명)에 .wslconfig 파일을 생성하여
  메모리를 넉넉히 할당하는 것을 권장합니다.


   1 # .wslconfig 예시
   2 [wsl2]
   3 memory=16GB  # 보유 램의 50~70% 권장
   4 processors=8



docker exec -it cvat_worker_annotation ldconfig -p | grep nvidia